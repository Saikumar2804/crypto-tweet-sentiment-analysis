{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Analyzing the Impact of Tweets on Cryptocurrency Market Trends Using LSTM-GRU Model\n", "This notebook outlines the steps to analyze the impact of cryptocurrency-related tweets on market trends using an LSTM-GRU model."]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Step 1: Data Loading and Preprocessing\n", "In this step, we will load the tweet data, clean it, and preprocess it for further analysis."]}, {"cell_type": "code", "metadata": {}, "source": ["# Importing necessary libraries\n", "import pandas as pd\n", "import re\n", "from nltk.corpus import stopwords\n", "from nltk.tokenize import word_tokenize\n", "from nltk.stem import WordNetLemmatizer\n", "import nltk\n", "\n", "# Download necessary NLTK resources\n", "nltk.download('punkt')\n", "nltk.download('stopwords')\n", "nltk.download('wordnet')\n", "\n", "# Load dataset\n", "tweets_df = pd.read_csv('path/to/your/crypto_tweet_dataset.csv')\n", "tweets_df.head()"]}, {"cell_type": "code", "metadata": {}, "source": ["# Cleaning the text data\n", "lemmatizer = WordNetLemmatizer()\n", "stop_words = set(stopwords.words('english'))\n", "\n", "def clean_text(text):\n", "    text = text.lower()\n", "    text = re.sub(r'http\\S+', '', text)\n", "    text = re.sub(r'[^a-zA-Z]', ' ', text)\n", "    tokens = word_tokenize(text)\n", "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n", "    return ' '.join(tokens)\n", "\n", "tweets_df['cleaned_text'] = tweets_df['text'].apply(clean_text)\n", "tweets_df[['text', 'cleaned_text']].head()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Step 2: Feature Extraction (Sentiment Analysis)\n", "In this step, we will perform sentiment analysis on the cleaned text and extract sentiment features."]}, {"cell_type": "code", "metadata": {}, "source": ["# Sentiment analysis using TextBlob\n", "from textblob import TextBlob\n", "\n", "def get_sentiment(text):\n", "    blob = TextBlob(text)\n", "    return blob.sentiment.polarity\n", "\n", "tweets_df['sentiment'] = tweets_df['cleaned_text'].apply(get_sentiment)\n", "tweets_df[['cleaned_text', 'sentiment']].head()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Step 3: Building the LSTM-GRU Model\n", "In this step, we will build a hybrid LSTM-GRU model to analyze the impact of tweets on cryptocurrency market trends."]}, {"cell_type": "code", "metadata": {}, "source": ["# Building the LSTM-GRU Model\n", "from keras.models import Sequential\n", "from keras.layers import LSTM, GRU, Dense, Embedding\n", "from sklearn.model_selection import train_test_split\n", "import numpy as np\n", "\n", "# Prepare data for the model (this is a simplified representation)\n", "X = np.array(tweets_df['cleaned_text'])  # Input features\n", "y = np.array(tweets_df['sentiment'])  # Target values (market trends)\n", "\n", "# Splitting the data into training and test sets\n", "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n", "\n", "# Defining the LSTM-GRU hybrid model\n", "model = Sequential()\n", "model.add(Embedding(input_dim=5000, output_dim=64, input_length=100))\n", "model.add(LSTM(units=128, return_sequences=True))\n", "model.add(GRU(units=64))\n", "model.add(Dense(1, activation='sigmoid'))\n", "\n", "# Compiling the model\n", "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n", "\n", "# Training the model\n", "model.fit(X_train, y_train, epochs=5, batch_size=32, validation_data=(X_test, y_test))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Step 4: Model Evaluation and Visualization\n", "In this step, we will evaluate the model's performance and visualize the results."]}, {"cell_type": "code", "metadata": {}, "source": ["# Evaluate the model\n", "loss, accuracy = model.evaluate(X_test, y_test)\n", "print(f'Test Accuracy: {accuracy}')\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Step 5: Save the Model\n", "In this step, we will save the trained LSTM-GRU model for future use."]}, {"cell_type": "code", "metadata": {}, "source": ["# Save the model\n", "model.save('crypto_lstm_gru_model.h5')"]}], "metadata": {}, "nbformat": 4, "nbformat_minor": 5}